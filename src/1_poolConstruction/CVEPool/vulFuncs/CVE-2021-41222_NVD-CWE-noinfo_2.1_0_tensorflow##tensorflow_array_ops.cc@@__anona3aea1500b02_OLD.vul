
      DimensionHandle split_dimension;
      ShapeHandle input = c->input(0);
      TF_RETURN_IF_ERROR(c->MakeDimForScalarInputWithNegativeIndexing(
          2, c->Rank(input), &split_dimension));
      int32_t num_outputs = c->num_outputs();
      int32_t rank = c->Rank(input);
      ShapeHandle output_shape;
      const Tensor* size_splits = c->input_tensor(1);
      if (rank == InferenceContext::kUnknownRank) 
        // If the rank of input tensor is unknown, then return unknown shapes.
        // Note that the shape of each output can be different.
        for (int i = 0; i < num_outputs; ++i) 
          c->set_output(i, c->UnknownShape());
        
       else if (rank == 0) 
        // Throw error if input is a scalar.
        return errors::InvalidArgument("Can't split scalars");
       else if (size_splits == nullptr && c->ValueKnown(split_dimension)) 
        // If split dimension is known, but the sizes are unknown, then
        // only the split dimension is unknown
        output_shape = input;
        for (int i = 0; i < num_outputs; ++i) 
          TF_RETURN_IF_ERROR(c->ReplaceDim(output_shape,
                                           c->Value(split_dimension),
                                           c->UnknownDim(), &output_shape));
          c->set_output(i, output_shape);
        
       else if (size_splits == nullptr && !c->ValueKnown(split_dimension)) 
        // If split dimension or tensor containing the split sizes is unknown,
        // then return unknown shapes of same rank as input. Note that each
        // output shape can be different since splitv doesn't always split
        // tensors evenly.
        for (int i = 0; i < num_outputs; ++i) 
          c->set_output(i, c->UnknownShapeOfRank(rank));
        
       else 
        // Determine the output shape if split dimension and split sizes are
        // known.
        int64_t split_dim = c->Value(split_dimension);
        TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, split_dim + 1, &input));
        std::vector<int64_t> data;
        if (size_splits->dtype() == DT_INT32) 
          data = AsInt64<int32>(size_splits, size_splits->shape().dim_size(0));
         else 
          data =
              AsInt64<int64_t>(size_splits, size_splits->shape().dim_size(0));
        
        if (num_outputs != data.size()) 
          return errors::InvalidArgument(
              "Length of size_splits should be equal to num_outputs");
        
        int64_t total_size = 0;
        bool has_neg_one = false;
        for (const auto size : data) 
          if (size == -1) 
            if (has_neg_one) 
              return errors::InvalidArgument(
                  "size_splits can only have one -1");
            
            has_neg_one = true;
           else 
            total_size += size;
          
        
        auto split_dim_size = c->Value(c->Dim(input, split_dim));
        // If the sizes of the splits are known, then
        // make sure that the sizes add up to the expected
        // dimension size, with the possibility of a -1.
        // Specify the full output shapes.
        for (int i = 0; i < num_outputs; ++i) 
          auto size = data[i];
          if (data[i] == -1 && c->ValueKnown(split_dim_size)) 
            size = split_dim_size - total_size;
          
          TF_RETURN_IF_ERROR(
              c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));
          c->set_output(i, output_shape);
        
        if (c->ValueKnown(split_dim_size)) 
          if (has_neg_one ? total_size > split_dim_size
                          : total_size != split_dim_size) 
            return errors::InvalidArgument(
                "can't split axis of size ", split_dim_size,
                " into pieces of size [", absl::StrJoin(data, ","), "]");
          
        
      

      return Status::OK();
    